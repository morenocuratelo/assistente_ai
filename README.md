# ğŸ“š Archivista AI v2.4.0 (Alpha 2.4) - **Phase 3: Intelligent Academic Ecosystem** ğŸ“ğŸ¤–

**Sistema Intelligente per l'Archiviazione e l'Interrogazione di Documenti con Architettura Multi-Pagina**

Archivista AI Ã¨ un'applicazione web avanzata che utilizza l'intelligenza artificiale per processare, indicizzare e rendere interrogabili documenti scientifici e accademici. Il sistema Ã¨ basato su LlamaIndex e offre un'interfaccia utente moderna costruita con Streamlit con architettura multi-pagina ottimizzata.

## âœ¨ Caratteristiche Principali

- ğŸ’¬ **Chat Multi-Modale**: Interfaccia conversazionale avanzata con supporto immagini e documenti
- ğŸ” **Ricerca Semantica**: Motore di ricerca intelligente con comprensione del contesto
- ğŸ“ **Editor Avanzato**: Modifica professionale delle anteprime con editor rich-text
- ğŸ—‚ï¸ **Archivio Intelligente**: Organizzazione automatica e categorizzazione dei documenti
- ğŸ“ **Planner Accademico**: Gestione completa corsi, lezioni e attivitÃ  didattiche
- ğŸ§  **Grafo della Conoscenza**: Mappa interattiva delle connessioni concettuali
- ğŸ® **Sistema Gamificato**: XP, achievement e monitoraggio progresso accademico
- ğŸ¤– **Elaborazione AI**: Estrazione automatica di metadati, riassunti e anteprime
- ğŸ”„ **Elaborazione Asincrona**: Processamento in background con Celery e Redis
- ğŸ³ **Containerizzazione**: Deployment semplificato con Docker
- ğŸ“Š **Dashboard Interattiva**: Interfaccia web moderna e responsiva
- ğŸ” **Persistenza Dati**: Database SQLite con backup automatico

## ğŸ“± Architettura Multi-Pagina

L'applicazione utilizza un'architettura multi-pagina ottimizzata per diverse funzionalitÃ :

### ğŸ’¬ **Chat** (Pagina Principale)
- **Interfaccia conversazionale** con i documenti
- **Supporto multimodale** (testo + immagini)
- **Ricerca semantica** in tempo reale
- **Chat history** e contesto persistente

### ğŸ—‚ï¸ **Archivio**
- **Esplorazione documenti** con filtri avanzati
- **Visualizzazione metadati** estratti dall'AI
- **Ricerca full-text** e semantica
- **Gestione categorie** e organizzazione

### ğŸ“ **Editor**
- **Editor rich-text avanzato** con Streamlit Quill
- **Modifica anteprime** generate dall'AI
- **Visualizzatore documenti** affiancato
- **Auto-salvataggio** e validazione modifiche

### âœ¨ **Nuovo**
- **Creazione documenti** direttamente nell'app
- **Template personalizzati** per diversi tipi di contenuto
- **Integrazione AI** per generazione assistita
- **Salvataggio automatico** nel database

## ğŸš€ Avvio Rapido

### âš¡ Iniziamo in 3 minuti!

#### Opzione 1: Docker (Raccomandato - PiÃ¹ Semplice)

```bash
# 1. Scarica e avvia tutto automaticamente
docker-compose up -d

# 2. Verifica che tutto funzioni
docker-compose ps

# 3. Apri l'applicazione
# ğŸŒ Web UI: http://localhost:8501
# ğŸ“Š Monitor: http://localhost:5555 (Flower dashboard)
```

#### Opzione 2: Installazione Manuale

```bash
# 1. Installa e avvia Redis
start_redis.bat

# 2. Installa dipendenze Python
pip install -r requirements.txt

# 3. Avvia il worker in background
start_celery_worker.bat

# 4. Avvia l'applicazione
streamlit run main.py

# 5. Apri http://localhost:8501
```

#### âš ï¸ Prerequisiti per Ollama (IA)

Prima di iniziare, assicurati che **Ollama** sia installato e in esecuzione:

```bash
# Verifica modelli disponibili
ollama list

# Se necessario, scarica i modelli richiesti
ollama pull llama3
ollama pull llava-llama3
```

## ğŸ“‹ Prerequisiti

- **Python**: 3.11+
- **Redis**: Server Redis in esecuzione
- **RAM**: Almeno 4GB
- **Spazio**: 2GB disponibile
- **Docker**: (Opzionale) Per deployment containerizzato

## ğŸ—ï¸ Architettura del Sistema

### Componenti Principali

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚    â”‚   Celery Worker â”‚    â”‚     Redis       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   (Message      â”‚
â”‚ - Interfaccia   â”‚    â”‚ - Task Processingâ”‚    â”‚    Broker)      â”‚
â”‚ - Upload File   â”‚    â”‚ - AI Processing â”‚    â”‚                 â”‚
â”‚ - Query Engine  â”‚    â”‚ - Indexing      â”‚    â”‚ - Task Queue    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   LlamaIndex    â”‚
                    â”‚                 â”‚
                    â”‚ - Vector Store  â”‚
                    â”‚ - Embeddings    â”‚
                    â”‚ - LLM Models    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tecnologie Utilizzate

- **Frontend**: Streamlit 1.49.1
- **AI Framework**: LlamaIndex 0.14.2
- **Task Queue**: Celery 5.5.3 + Redis 5.2.1
- **Database**: SQLite con SQLAlchemy
- **Document Processing**: PyMuPDF, python-docx
- **Container**: Docker + Docker Compose
- **ML Models**: HuggingFace Transformers, Sentence Transformers

## ğŸ“ Struttura del Progetto

```
archivista-ai/
â”œâ”€â”€ ğŸ“„ main.py                 # Applicazione Streamlit principale
â”œâ”€â”€ ğŸ“„ tasks.py                # Configurazione Celery e task
â”œâ”€â”€ ğŸ“„ archivista_processing.py # Task specifiche per l'archiviazione
â”œâ”€â”€ ğŸ“„ config.py               # Configurazione LlamaIndex
â”œâ”€â”€ ğŸ“„ file_utils.py           # UtilitÃ  per la gestione file
â”œâ”€â”€ ğŸ“„ tools.py                # Strumenti AI e ricerca web
â”œâ”€â”€ ğŸ“„ prompt_manager.py       # Gestione prompt LLM
â”œâ”€â”€ ğŸ“„ requirements.txt        # Dipendenze Python
â”œâ”€â”€ ğŸ“„ requirements.in         # Dipendenze di base
â”œâ”€â”€ ğŸ³ Dockerfile             # Containerizzazione
â”œâ”€â”€ ğŸ³ docker-compose.yml     # Orchestrazione servizi
â”œâ”€â”€ ğŸ“š CELERY_README.md       # Documentazione Celery
â”œâ”€â”€ ğŸ“š DOCKER_README.md       # Documentazione Docker
â”œâ”€â”€ ğŸ“š README.md              # Questo file
â”œâ”€â”€ ğŸ“ pages/                 # Pagine dell'applicazione multi-pagina
â”‚   â”œâ”€â”€ 1_ğŸ’¬_Chat.py          # Chat principale (conversazionale)
â”‚   â”œâ”€â”€ 2_ğŸ—‚ï¸_Archivio.py      # Esplorazione e gestione archivio
â”‚   â”œâ”€â”€ 3_ğŸ“_Editor.py         # Editor avanzato anteprime
â”‚   â”œâ”€â”€ 4_âœ¨_Nuovo.py          # Creazione nuovi documenti
â”‚   â”œâ”€â”€ 5_ğŸ“_Carriera.py       # Planner accademico con IA
â”‚   â””â”€â”€ 6_ğŸ§ _Grafo.py          # Grafo delle connessioni concettuali
â””â”€â”€ ğŸ“ db_memoria/            # Database e indici
    â”œâ”€â”€ metadata.sqlite       # Database metadati
    â”œâ”€â”€ index_store.json      # Store degli indici
    â””â”€â”€ vector_store.json     # Vector store
```

## ğŸ”§ Configurazione

### Variabili d'Ambiente

```bash
# Redis
REDIS_URL=redis://localhost:6379/0

# LLM (Ollama)
OLLAMA_BASE_URL=http://localhost:11434

# Directory
DOCS_TO_PROCESS_DIR=documenti_da_processare
PROCESSED_DOCS_DIR=documenti_archiviati
DB_STORAGE_DIR=db_memoria
```

### Configurazione LLM

Il sistema utilizza un'architettura duale per ottimizzare le prestazioni:

- **llama3**: Per l'indicizzazione e l'estrazione metadati (veloce e stabile)
- **llava-llama3**: Per la chat multimodale (supporta testo e immagini)

**Prerequisiti:**
- **Ollama** deve essere installato e in esecuzione sul sistema host
- I modelli `llama3` e `llava-llama3` devono essere scaricati

**Modelli Supportati:**
- **Ollama** (default): Modelli locali con supporto multimodale
- **OpenAI**: GPT-3.5, GPT-4 (richiede API key)
- **HuggingFace**: Modelli open-source

## ğŸ“– Guida Utente

### Utilizzo Base

1. **Caricamento Documenti**
   - Copia i file PDF/DOCX nella cartella `documenti_da_processare/`
   - Clicca su "ğŸ” Scansiona nuovi documenti" nell'interfaccia
   - I documenti vengono processati automaticamente in background

2. **Ricerca e Interrogazione**
   - Utilizza la chat per interrogare i documenti
   - Applica filtri per autore, anno, o documento specifico
   - Visualizza anteprime AI e metadati estratti

3. **Gestione Archivio**
   - Modifica metadati dei documenti
   - Elimina documenti non piÃ¹ necessari
   - Esporta risultati di ricerca

### FunzionalitÃ  Avanzate

- **Ricerca Semantica**: Comprensione del contesto e significato
- **Filtri Intelligenti**: Filtraggio per metadati e contenuto
- **Anteprime AI**: Riassunti automatici generati dall'IA
- **Elaborazione Batch**: Processamento multiplo di documenti
- **Monitoraggio**: Dashboard per tracciare l'elaborazione

## ğŸ³ Deployment con Docker

### Servizi Disponibili

- **Webapp**: Interfaccia utente (http://localhost:8501)
- **Worker**: Elaborazione background documenti
- **Redis**: Message broker e cache
- **Flower**: Monitoraggio task (http://localhost:5555)

### Comandi Docker

```bash
# Avvia tutti i servizi
docker-compose up -d

# Visualizza log
docker-compose logs -f

# Arresta servizi
docker-compose down

# Ricostruisci immagini
docker-compose up --build -d
```

## ğŸ” Troubleshooting

### Problemi Comuni

1. **Ollama non raggiungibile**
   ```bash
   # Verifica che Ollama sia in esecuzione
   ollama list

   # Avvia Ollama
   ollama serve

   # Scarica i modelli necessari
   ollama pull llama3
   ollama pull llava-llama3
   ```

2. **Redis non si avvia**
   ```bash
   # Verifica che Redis sia installato
   redis-cli ping

   # Avvia Redis manualmente
   redis-server
   ```

3. **Worker Celery non risponde**
   ```bash
   # Verifica connessione Redis
   python -c "import redis; r=redis.Redis(); print(r.ping())"

   # Riavvia worker
   docker-compose restart worker
   ```

4. **Documenti non processati**
   ```bash
   # Verifica log worker
   docker-compose logs worker

   # Controlla cartella documenti
   ls -la documenti_da_processare/
   ```

5. **Errore "LLM non disponibile"**
   - Verifica che Ollama sia in esecuzione
   - Controlla che i modelli siano scaricati
   - Verifica la connessione di rete
   - Controlla i log dell'applicazione

6. **Errore modulo "statistics"**
   - Il modulo `statistics.py` Ã¨ stato rinominato in `archive_statistics.py`
   - Se vedi errori di importazione, aggiorna i tuoi script
   - Usa: `from archive_statistics import get_comprehensive_stats`

### Log e Debug

```bash
# Log completi
docker-compose logs -f

# Log specifico servizio
docker-compose logs webapp
docker-compose logs worker

# Accesso container
docker-compose exec webapp bash
docker-compose exec worker bash
```

## ğŸ“ˆ Performance

### Ottimizzazioni

- **Worker Paralleli**: Configura piÃ¹ worker per elaborazione simultanea
- **Chunk Size**: Ottimizza la dimensione dei chunk per l'indicizzazione
- **Cache Redis**: Utilizza Redis per caching intelligente
- **Modelli LLM**: Scegli modelli appropriati per le tue esigenze

### Monitoraggio

- **Flower Dashboard**: Monitora task e performance
- **Redis Insight**: Analizza l'utilizzo della memoria
- **Log Analysis**: Controlla i log per identificare bottleneck

## ğŸ”’ Sicurezza

- **Container Isolation**: Servizi isolati in container Docker
- **Network Security**: Configurazione di rete sicura
- **Data Encryption**: Crittografia dei dati sensibili
- **Access Control**: Controllo degli accessi all'interfaccia

## ğŸ¤ Contribuire

### Linee Guida per i Contributi

1. Fork il repository
2. Crea un branch per la tua feature (`git checkout -b feature/nuova-feature`)
3. Committa i tuoi cambiamenti (`git commit -am 'Aggiungi nuova feature'`)
4. Push al branch (`git push origin feature/nuova-feature`)
5. Crea una Pull Request

### Struttura del Codice

- **ModularitÃ **: Codice organizzato in moduli separati
- **Documentazione**: Commenti e docstring per tutte le funzioni
- **Testing**: Test unitari per le funzionalitÃ  critiche
- **Type Hints**: Annotazioni di tipo per Python

## ğŸ“š Documentazione Dettagliata

- **[Guida Celery](CELERY_README.md)**: Configurazione task queue e Redis
- **[Guida Docker](DOCKER_README.md)**: Deployment containerizzato
- **[API Reference](docs/api.md)**: Documentazione API (se disponibile)

## ğŸ”„ Changelog

### Versione 2.4.0 (Alpha 2.4) - Novembre 2025 - **Phase 3: Intelligent Academic Ecosystem** ğŸ“ğŸ¤–

**ğŸ¯ Rivoluzione dell'Apprendimento: Dal Document Organizer all'AI Study Companion**

**ğŸ§  Sistema Gamificato:**
- âœ… **XP & Achievement System**: Guadagna punteggi per attivitÃ  di apprendimento
- âœ… **Gamification del Learning**: Achievement, badge e traguardi motivazionali
- âœ… **Tracking Performance**: Progressi quanti e storici di apprendimento
- âœ… **Studio Sessions**: Registrazione sessioni di studio con rating produttivitÃ 

**ğŸ“ Academic Planner Integrato:**
- âœ… **6Â° Pagina Specializzata**: Carriera accademica completa
- âœ… **Course Management**: Corsi universitari con lezioni e materiali associati
- âœ… **Task Generation AI**: Creazione automatica di attivitÃ  di apprendimento
- âœ… **Study Planning**: Pianificazione intelligente degli obiettivi accademici

**ğŸ§  Dynamic Knowledge Graph:**
- âœ… **7Â° Pagina**: Grafo interattivo delle connessioni concettuali
- âœ… **Entity Extraction**: entities concettuali, teorie, autori, formule
- âœ… **Relationship Mapping**: Scoperta connessioni semantiche con confidence scores
- âœ… **Interactive Navigation**: Esplorazione entitÃ  e loro vicinanza concettuale

**ğŸ“Š Database Evoluto:**
- âœ… **Nuove Tabelle**: concept_entities, concept_relationships, user_xp, achievements
- âœ… **Graph Database Capabilities**: FunzionalitÃ  avanzate per mappare conoscenze
- âœ… **Entity-Relationship Storage**: Memorizzazione relazioni fra concetti

**ğŸ¤– Processing Pipeline Esteso:**
- âœ… **Academic AI Prompts**: Analisi didattica specializzata per NLP
- âœ… **Knowledge Discovery**: Algoritmi avanzati per trovare connessioni nascoste
- âœ… **Multi-layer Analysis**: Keywords + Entities + Relationships profondi

**ğŸ”„ User Experience Evoluta:**
- âœ… **Cross-page Navigation**: Collegamenti fra grafi e materiali accademici
- âœ… **Unified Academic Dashboard**: Vista unificata del progresso didattico
- âœ… **Smart Recommendations**: Suggerimenti basati sui pattern di apprendimento

**ğŸ”§ Technical Enhancements:**
- âœ… **NetworkX Integration**: Libreria per visualizzazione grafi complessa
- âœ… **Optimized Graph Operations**: Performance elevate per big knowledge graphs
- âœ… **Scalable Entity Storage**: Database ottimizzato per migliaia di entity

**ğŸ“š Certification & Achievements:**
- âœ… **Study Streaks**: Ricompense per apprendimento consistente
- âœ… **Course Completion**: Badge per completamento corsi
- âœ… **Knowledge Master**: Traguardi per profonditÃ  di comprensione

### Versione 2.2.0 (Alpha 2.2) - Dicembre 2024

**ğŸ†• Nuove FunzionalitÃ :**
- âœ… Sistema di elaborazione asincrona Celery
- âœ… Containerizzazione Docker completa
- âœ… Dashboard di monitoraggio Flower
- âœ… Sistema di status in tempo reale

**ğŸ”§ Miglioramenti:**
- âœ… Ottimizzazione performance processamento
- âœ… Migliore gestione errori e recovery
- âœ… Interfaccia utente migliorata

### Versioni Precedenti

- **v1.0.0**: Release iniziale con funzionalitÃ  base

## ğŸ“ Supporto

### Community

- **GitHub Issues**: Segnala bug e richiedi feature
- **Discussions**: Discussioni sulla community
- **Documentation**: Controlla la documentazione aggiornata

### Contatti

- **Email**: support@archivista-ai.com
- **GitHub**: https://github.com/your-repo/archivista-ai
- **Documentation**: https://docs.archivista-ai.com

## ğŸ“„ Licenza

Questo progetto Ã¨ distribuito sotto licenza MIT. Vedi il file `LICENSE` per i dettagli.

## ğŸ™ Ringraziamenti

- **LlamaIndex Team**: Per l'eccellente framework AI
- **Streamlit Team**: Per l'interfaccia web intuitiva
- **Celery Team**: Per il sistema di task queue robusto
- **Open Source Community**: Per le librerie e tool utilizzati

---

**Archivista AI** - Porta l'intelligenza artificiale nel tuo archivio documentale ğŸš€
