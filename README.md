# ğŸ“š Archivista AI v2.5.0 (Alpha 2.5) - **Phase 4: Production-Ready Intelligent Document Management** ğŸš€ğŸ­

**Sistema Enterprise-Ready per l'Archiviazione, Elaborazione e Monitoraggio di Documenti con Framework di Diagnosi Errori Avanzato**

Archivista AI Ã¨ un'applicazione web avanzata **production-ready** che utilizza l'intelligenza artificiale per processare, indicizzare e rendere interrogabili documenti scientifici e accademici pesanti. Il sistema integra un **framework completo di diagnosi e gestione errori** con **monitoraggio avanzato** e **deployment ottimizzato per documenti di grandi dimensioni**.

## âœ¨ Caratteristiche Principali

### ğŸ¤– **Core AI Features**
- ğŸ’¬ **Chat Multi-Modale**: Interfaccia conversazionale avanzata con supporto immagini e documenti
- ğŸ” **Ricerca Semantica**: Motore di ricerca intelligente con comprensione del contesto
- ğŸ“ **Editor Avanzato**: Modifica professionale delle anteprime con editor rich-text
- ğŸ—‚ï¸ **Archivio Intelligente**: Organizzazione automatica e categorizzazione dei documenti
- ğŸ“ **Planner Accademico**: Gestione completa corsi, lezioni e attivitÃ  didattiche
- ğŸ§  **Grafo della Conoscenza**: Mappa interattiva delle connessioni concettuali con confidence scoring
- ğŸ® **Sistema Gamificato**: XP, achievement e monitoraggio progresso accademico

### ğŸš¨ **Enterprise Error Management**
- ğŸ” **Framework Diagnosi Errori**: Classificazione automatica errori con 10 stati di processamento
- ğŸ”„ **Sistema Retry Intelligente**: Backoff esponenziale con limiti categoria-specifici
- ğŸš« **Quarantena Automatica**: Isolamento file problematici con analisi dettagliata
- ğŸ“Š **Monitoraggio Avanzato**: Metriche real-time di sistema, processamento ed errori
- ğŸ“§ **Alerting Intelligente**: Notifiche email per condizioni critiche con anti-spam
- ğŸ’š **Health Checks**: Verifica salute componenti con report dettagliati

### ğŸ­ **Production-Ready Features**
- ğŸ³ **Containerizzazione Ottimizzata**: Multi-stage build con sicurezza hardening
- âš™ï¸ **Configurazione Produzione**: Resource limits ottimizzati per documenti pesanti
- ğŸ”§ **Deployment Automatizzato**: Script automatico con verifica prerequisiti
- ğŸ“ˆ **Performance Monitoring**: Tracking throughput e utilizzo risorse
- ğŸ’¾ **Backup Automatici**: Backup giornalieri con retention management
- ğŸŒ **Load Balancing**: Architettura high-availability per scalability

### ğŸ”§ **Technical Excellence**
- ğŸ¤– **Elaborazione AI**: Estrazione automatica di metadati, riassunti e anteprime
- ğŸ”„ **Elaborazione Asincrona**: Processamento in background con Celery e Redis
- ğŸ“Š **Dashboard Unificata**: Interfaccia web moderna con integrazione completa
- ğŸ” **Persistenza Dati**: Database SQLite avanzato con backup automatico
- ğŸ“‹ **Logging Strutturato**: Log JSON con correlation ID e analisi avanzata

## ğŸ“± Architettura Multi-Pagina

L'applicazione utilizza un'architettura multi-pagina ottimizzata per diverse funzionalitÃ :

### ğŸ’¬ **Chat** (Pagina Principale)
- **Interfaccia conversazionale** con i documenti
- **Supporto multimodale** (testo + immagini)
- **Ricerca semantica** in tempo reale
- **Chat history** e contesto persistente

### ğŸ—‚ï¸ **Archivio**
- **Esplorazione documenti** con filtri avanzati
- **Visualizzazione metadati** estratti dall'AI
- **Ricerca full-text** e semantica
- **Gestione categorie** e organizzazione

### ğŸ“ **Editor**
- **Editor rich-text avanzato** con Streamlit Quill
- **Modifica anteprime** generate dall'AI
- **Visualizzatore documenti** affiancato
- **Auto-salvataggio** e validazione modifiche

### âœ¨ **Nuovo**
- **Creazione documenti** direttamente nell'app
- **Template personalizzati** per diversi tipi di contenuto
- **Integrazione AI** per generazione assistita
- **Salvataggio automatico** nel database

## ğŸš€ Avvio Rapido

### âš¡ Iniziamo in 3 minuti!

#### Opzione 1: Deployment Produzione (Raccomandato per Documenti Pesanti)

```bash
# 1. Deploy automatico ottimizzato per documenti pesanti
chmod +x deploy.sh
./deploy.sh

# 2. Verifica servizi production-ready
docker-compose -f docker-compose.prod.yml ps

# 3. Accesso interfacce enterprise
# ğŸŒ Dashboard Unificata: http://localhost:8501
# ğŸ“Š Monitoraggio Celery: http://localhost:5555
# ğŸ”¬ Monitoraggio Avanzato: http://localhost:8501 (tab Monitoraggio)
```

#### Opzione 2: Sviluppo Standard

```bash
# 1. Avvia servizi base
docker-compose up -d

# 2. Verifica servizi
docker-compose ps

# 3. Accesso sviluppo
# ğŸŒ Web UI: http://localhost:8501
# ğŸ“Š Monitor: http://localhost:5555
```

#### Opzione 3: Installazione Manuale

```bash
# 1. Installa e avvia Redis
start_redis.bat

# 2. Installa dipendenze Python (include framework errori avanzato)
pip install -r requirements.txt

# 3. Avvia worker con configurazione ottimizzata
start_celery_worker.bat

# 4. Avvia applicazione con framework diagnosi errori
streamlit run main_new_architecture.py

# 5. Accesso: http://localhost:8501
```

#### âš ï¸ Prerequisiti per Ollama (IA)

Prima di iniziare, assicurati che **Ollama** sia installato e in esecuzione:

```bash
# Verifica modelli disponibili
ollama list

# Se necessario, scarica i modelli richiesti
ollama pull llama3        # Per processamento documenti
ollama pull llava-llama3  # Per chat multimodale
```

### ğŸ¯ Deployment Produzione per Documenti Pesanti

Per utilizzo con molti documenti pesanti, utilizza il deployment ottimizzato:

```bash
# Deploy produzione completo
./deploy.sh

# Servizi ottimizzati:
# ğŸŸ¡ Webapp (4GB RAM) - Dashboard con framework errori
# ğŸŸ¢ Worker (8GB RAM) - Processamento documenti pesanti
# ğŸ”´ Redis (256MB) - Message broker ottimizzato
# ğŸŸ  Flower - Monitoraggio avanzato
# ğŸ”µ Beat - Scheduler task periodici
# ğŸŸ£ Backup - Backup automatici giornalieri
```

**Interfacce Disponibili:**
- ğŸŒ **Dashboard Unificata**: http://localhost:8501 (tutte le funzionalitÃ  integrate)
- ğŸ“Š **Monitoraggio Celery**: http://localhost:5555 (task queue avanzata)
- ğŸ”¬ **Monitoraggio Sistema**: http://localhost:8501 (health checks e metriche)
- ğŸ“‹ **Log Centralizzati**: Accessibili tramite dashboard

## ğŸ“‹ Prerequisiti

- **Python**: 3.11+
- **Redis**: Server Redis in esecuzione
- **RAM**: Almeno 4GB
- **Spazio**: 2GB disponibile
- **Docker**: (Opzionale) Per deployment containerizzato

## ğŸ—ï¸ Architettura del Sistema

### Componenti Principali

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚    â”‚   Celery Worker â”‚    â”‚     Redis       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   (Message      â”‚
â”‚ - Interfaccia   â”‚    â”‚ - Task Processingâ”‚    â”‚    Broker)      â”‚
â”‚ - Upload File   â”‚    â”‚ - AI Processing â”‚    â”‚                 â”‚
â”‚ - Query Engine  â”‚    â”‚ - Indexing      â”‚    â”‚ - Task Queue    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   LlamaIndex    â”‚
                    â”‚                 â”‚
                    â”‚ - Vector Store  â”‚
                    â”‚ - Embeddings    â”‚
                    â”‚ - LLM Models    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tecnologie Utilizzate

- **Frontend**: Streamlit 1.49.1
- **AI Framework**: LlamaIndex 0.14.2
- **Task Queue**: Celery 5.5.3 + Redis 5.2.1
- **Database**: SQLite con SQLAlchemy
- **Document Processing**: PyMuPDF, python-docx
- **Container**: Docker + Docker Compose
- **ML Models**: HuggingFace Transformers, Sentence Transformers

## ğŸ“ Struttura del Progetto

```
archivista-ai/
â”œâ”€â”€ ğŸ“„ main.py                 # Applicazione Streamlit principale
â”œâ”€â”€ ğŸ“„ tasks.py                # Configurazione Celery e task
â”œâ”€â”€ ğŸ“„ archivista_processing.py # Task specifiche per l'archiviazione
â”œâ”€â”€ ğŸ“„ config.py               # Configurazione LlamaIndex
â”œâ”€â”€ ğŸ“„ file_utils.py           # UtilitÃ  per la gestione file
â”œâ”€â”€ ğŸ“„ tools.py                # Strumenti AI e ricerca web
â”œâ”€â”€ ğŸ“„ prompt_manager.py       # Gestione prompt LLM
â”œâ”€â”€ ğŸ“„ requirements.txt        # Dipendenze Python
â”œâ”€â”€ ğŸ“„ requirements.in         # Dipendenze di base
â”œâ”€â”€ ğŸ³ Dockerfile             # Containerizzazione
â”œâ”€â”€ ğŸ³ docker-compose.yml     # Orchestrazione servizi
â”œâ”€â”€ ğŸ“š CELERY_README.md       # Documentazione Celery
â”œâ”€â”€ ğŸ“š DOCKER_README.md       # Documentazione Docker
â”œâ”€â”€ ğŸ“š README.md              # Questo file
â”œâ”€â”€ ğŸ“ pages/                 # Pagine dell'applicazione multi-pagina
â”‚   â”œâ”€â”€ 1_ğŸ’¬_Chat.py          # Chat principale (conversazionale)
â”‚   â”œâ”€â”€ 2_ğŸ—‚ï¸_Archivio.py      # Esplorazione e gestione archivio
â”‚   â”œâ”€â”€ 3_ğŸ“_Editor.py         # Editor avanzato anteprime
â”‚   â”œâ”€â”€ 4_âœ¨_Nuovo.py          # Creazione nuovi documenti
â”‚   â”œâ”€â”€ 5_ğŸ“_Carriera.py       # Planner accademico con IA
â”‚   â””â”€â”€ 6_ğŸ§ _Grafo.py          # Grafo delle connessioni concettuali
â””â”€â”€ ğŸ“ db_memoria/            # Database e indici
    â”œâ”€â”€ metadata.sqlite       # Database metadati
    â”œâ”€â”€ index_store.json      # Store degli indici
    â””â”€â”€ vector_store.json     # Vector store
```

## ğŸ”§ Configurazione

### Variabili d'Ambiente

```bash
# Redis
REDIS_URL=redis://localhost:6379/0

# LLM (Ollama)
OLLAMA_BASE_URL=http://localhost:11434

# Directory
DOCS_TO_PROCESS_DIR=documenti_da_processare
PROCESSED_DOCS_DIR=documenti_archiviati
DB_STORAGE_DIR=db_memoria
```

### Configurazione LLM

Il sistema utilizza un'architettura duale per ottimizzare le prestazioni:

- **llama3**: Per l'indicizzazione e l'estrazione metadati (veloce e stabile)
- **llava-llama3**: Per la chat multimodale (supporta testo e immagini)

**Prerequisiti:**
- **Ollama** deve essere installato e in esecuzione sul sistema host
- I modelli `llama3` e `llava-llama3` devono essere scaricati

**Modelli Supportati:**
- **Ollama** (default): Modelli locali con supporto multimodale
- **OpenAI**: GPT-3.5, GPT-4 (richiede API key)
- **HuggingFace**: Modelli open-source

## ğŸ“– Guida Utente

### Utilizzo Base

1. **Caricamento Documenti**
   - Copia i file PDF/DOCX nella cartella `documenti_da_processare/`
   - Clicca su "ğŸ” Scansiona nuovi documenti" nell'interfaccia
   - I documenti vengono processati automaticamente in background

2. **Ricerca e Interrogazione**
   - Utilizza la chat per interrogare i documenti
   - Applica filtri per autore, anno, o documento specifico
   - Visualizza anteprime AI e metadati estratti

3. **Gestione Archivio**
   - Modifica metadati dei documenti
   - Elimina documenti non piÃ¹ necessari
   - Esporta risultati di ricerca

### FunzionalitÃ  Avanzate

- **Ricerca Semantica**: Comprensione del contesto e significato
- **Filtri Intelligenti**: Filtraggio per metadati e contenuto
- **Anteprime AI**: Riassunti automatici generati dall'IA
- **Elaborazione Batch**: Processamento multiplo di documenti
- **Monitoraggio**: Dashboard per tracciare l'elaborazione

## ğŸ³ Deployment con Docker

### Servizi Disponibili

- **Webapp**: Interfaccia utente (http://localhost:8501)
- **Worker**: Elaborazione background documenti
- **Redis**: Message broker e cache
- **Flower**: Monitoraggio task (http://localhost:5555)

### Comandi Docker

```bash
# Avvia tutti i servizi
docker-compose up -d

# Visualizza log
docker-compose logs -f

# Arresta servizi
docker-compose down

# Ricostruisci immagini
docker-compose up --build -d
```

## ğŸ” Troubleshooting

### Problemi Comuni

1. **Ollama non raggiungibile**
   ```bash
   # Verifica che Ollama sia in esecuzione
   ollama list

   # Avvia Ollama
   ollama serve

   # Scarica i modelli necessari
   ollama pull llama3
   ollama pull llava-llama3
   ```

2. **Redis non si avvia**
   ```bash
   # Verifica che Redis sia installato
   redis-cli ping

   # Avvia Redis manualmente
   redis-server
   ```

3. **Worker Celery non risponde**
   ```bash
   # Verifica connessione Redis
   python -c "import redis; r=redis.Redis(); print(r.ping())"

   # Riavvia worker
   docker-compose restart worker
   ```

4. **Documenti non processati**
   ```bash
   # Verifica log worker
   docker-compose logs worker

   # Controlla cartella documenti
   ls -la documenti_da_processare/
   ```

5. **Errore "LLM non disponibile"**
   - Verifica che Ollama sia in esecuzione
   - Controlla che i modelli siano scaricati
   - Verifica la connessione di rete
   - Controlla i log dell'applicazione

6. **Errore modulo "statistics"**
   - Il modulo `statistics.py` Ã¨ stato rinominato in `archive_statistics.py`
   - Se vedi errori di importazione, aggiorna i tuoi script
   - Usa: `from archive_statistics import get_comprehensive_stats`

### Log e Debug

```bash
# Log completi
docker-compose logs -f

# Log specifico servizio
docker-compose logs webapp
docker-compose logs worker

# Accesso container
docker-compose exec webapp bash
docker-compose exec worker bash
```

## ğŸ“ˆ Performance

### Ottimizzazioni

- **Worker Paralleli**: Configura piÃ¹ worker per elaborazione simultanea
- **Chunk Size**: Ottimizza la dimensione dei chunk per l'indicizzazione
- **Cache Redis**: Utilizza Redis per caching intelligente
- **Modelli LLM**: Scegli modelli appropriati per le tue esigenze

### Monitoraggio

- **Flower Dashboard**: Monitora task e performance
- **Redis Insight**: Analizza l'utilizzo della memoria
- **Log Analysis**: Controlla i log per identificare bottleneck

## ğŸ”’ Sicurezza

- **Container Isolation**: Servizi isolati in container Docker
- **Network Security**: Configurazione di rete sicura
- **Data Encryption**: Crittografia dei dati sensibili
- **Access Control**: Controllo degli accessi all'interfaccia

## ğŸ¤ Contribuire

### Linee Guida per i Contributi

1. Fork il repository
2. Crea un branch per la tua feature (`git checkout -b feature/nuova-feature`)
3. Committa i tuoi cambiamenti (`git commit -am 'Aggiungi nuova feature'`)
4. Push al branch (`git push origin feature/nuova-feature`)
5. Crea una Pull Request

### Struttura del Codice

- **ModularitÃ **: Codice organizzato in moduli separati
- **Documentazione**: Commenti e docstring per tutte le funzioni
- **Testing**: Test unitari per le funzionalitÃ  critiche
- **Type Hints**: Annotazioni di tipo per Python

## ğŸ“š Documentazione Dettagliata

### ğŸš¨ **Framework Diagnosi Errori**
- **[Framework Errori](error_diagnosis_framework.py)**: Sistema completo diagnosi e gestione errori
- **[Sistema Retry](retry_framework.py)**: Retry intelligente con backoff esponenziale
- **[Monitoraggio Avanzato](advanced_monitoring.py)**: Metriche e alerting avanzati

### ğŸ³ **Deployment Produzione**
- **[Deploy Produzione](PRODUCTION_README.md)**: Guida completa deployment enterprise
- **[Docker Produzione](docker-compose.prod.yml)**: Configurazione ottimizzata documenti pesanti
- **[Script Deploy](deploy.sh)**: Automazione deployment con verifiche

### ğŸ”§ **Documentazione Tecnica**
- **[Guida Celery](CELERY_README.md)**: Configurazione task queue e Redis
- **[Guida Docker](DOCKER_README.md)**: Deployment containerizzato
- **[API Reference](docs/api.md)**: Documentazione API (se disponibile)

### ğŸ“Š **Dashboard e Monitoraggio**
- **[Dashboard Unificata](unified_dashboard.py)**: Interfaccia integrata tutti i componenti
- **[Monitoraggio Dashboard](monitoring_dashboard.py)**: Dashboard dedicata monitoraggio
- **[Demo Integrazione](integration_demo.py)**: Demo completa tutti i framework

## ğŸ”„ Changelog

### Versione 3.0.0 - Ottobre 2025 - **Phase 4: Production-Ready Enterprise Document Management** ğŸš€ğŸ­

**ğŸ­ Rivoluzione Enterprise: Dal Sistema Personale al Framework Aziendale**

**ğŸš¨ Framework Completo Diagnosi e Gestione Errori:**
- âœ… **10 Stati di Processamento**: PENDING â†’ QUEUED â†’ PROCESSING â†’ FAILED_* â†’ COMPLETED
- âœ… **Classificazione Automatica Errori**: Categorizzazione intelligente per tipo e severitÃ 
- âœ… **Sistema Quarantena**: Isolamento automatico file problematici con metadati
- âœ… **Logging Strutturato**: Log JSON con correlation ID e analisi avanzata
- âœ… **Error Recovery**: Strategie di recovery automatico con retry intelligente

**ğŸ”„ Sistema Retry Avanzato:**
- âœ… **Backoff Esponenziale**: Algoritmo intelligente con jitter per evitare thundering herd
- âœ… **Retry Categoria-Specifici**: Limiti diversi basati su tipo errore (IOError: 5 retry, APIError: 2 retry)
- âœ… **Queue Management**: Gestione code prioritÃ  per documenti pesanti
- âœ… **Smart Retry Scheduling**: Calcolo automatico tempi ottimali per retry
- âœ… **Retry Analytics**: Monitoraggio e analisi pattern retry

**ğŸ“Š Monitoraggio e Alerting Avanzato:**
- âœ… **Metriche Real-time**: Sistema, processamento, errori, performance
- âœ… **Health Checks Multi-componente**: Database, AI services, file system, worker
- âœ… **Alerting Intelligente**: Email notifications con anti-spam e soglie configurabili
- âœ… **Dashboard Unificata**: Integrazione completa tutti i componenti
- âœ… **Performance Tracking**: Throughput, utilizzo risorse, trend storici

**ğŸ­ Deployment Produzione Ottimizzato:**
- âœ… **Docker Multi-stage**: Build ottimizzato con sicurezza hardening
- âœ… **Resource Management**: 8GB worker, 4GB webapp per documenti pesanti
- âœ… **Automated Backup**: Backup giornalieri con retention 7 giorni
- âœ… **Log Rotation**: Gestione automatica log con compressione
- âœ… **Production Script**: Deploy automatico con verifiche prerequisiti

**ğŸ›ï¸ Dashboard Integration:**
- âœ… **Unified Interface**: Dashboard singola per tutti i componenti
- âœ… **Real-time Progress**: Tracking live progresso processamento
- âœ… **Failed Files Management**: Interface interattiva gestione file problematici
- âœ… **Error Trend Analysis**: Analisi pattern e trend errori storici
- âœ… **Interactive Actions**: Azioni correttive direttamente da dashboard

**ğŸ”§ Technical Architecture:**
- âœ… **Modular Framework**: Componenti indipendenti e integrabili
- âœ… **Production Configuration**: File configurazione ottimizzati documenti pesanti
- âœ… **Security Hardening**: User non-root, network isolation, resource limits
- âœ… **Scalability Ready**: Architettura predisposta per scaling orizzontale
- âœ… **Enterprise Monitoring**: Integrazione Prometheus/Grafana ready

### Versione 2.4.0 (Alpha 2.4) - Novembre 2025 - **Phase 3: Intelligent Academic Ecosystem** ğŸ“ğŸ¤–

**ğŸ¯ Rivoluzione dell'Apprendimento: Dal Document Organizer all'AI Study Companion**

**ğŸ§  Sistema Gamificato:**
- âœ… **XP & Achievement System**: Guadagna punteggi per attivitÃ  di apprendimento
- âœ… **Gamification del Learning**: Achievement, badge e traguardi motivazionali
- âœ… **Tracking Performance**: Progressi quanti e storici di apprendimento
- âœ… **Studio Sessions**: Registrazione sessioni di studio con rating produttivitÃ 

**ğŸ“ Academic Planner Integrato:**
- âœ… **6Â° Pagina Specializzata**: Carriera accademica completa
- âœ… **Course Management**: Corsi universitari con lezioni e materiali associati
- âœ… **Task Generation AI**: Creazione automatica di attivitÃ  di apprendimento
- âœ… **Study Planning**: Pianificazione intelligente degli obiettivi accademici

**ğŸ§  Dynamic Knowledge Graph:**
- âœ… **7Â° Pagina**: Grafo interattivo delle connessioni concettuali
- âœ… **Entity Extraction**: entities concettuali, teorie, autori, formule
- âœ… **Relationship Mapping**: Scoperta connessioni semantiche con confidence scores
- âœ… **Interactive Navigation**: Esplorazione entitÃ  e loro vicinanza concettuale

**ğŸ“Š Database Evoluto:**
- âœ… **Nuove Tabelle**: concept_entities, concept_relationships, user_xp, achievements
- âœ… **Graph Database Capabilities**: FunzionalitÃ  avanzate per mappare conoscenze
- âœ… **Entity-Relationship Storage**: Memorizzazione relazioni fra concetti

**ğŸ¤– Processing Pipeline Esteso:**
- âœ… **Academic AI Prompts**: Analisi didattica specializzata per NLP
- âœ… **Knowledge Discovery**: Algoritmi avanzati per trovare connessioni nascoste
- âœ… **Multi-layer Analysis**: Keywords + Entities + Relationships profondi

**ğŸ”„ User Experience Evoluta:**
- âœ… **Cross-page Navigation**: Collegamenti fra grafi e materiali accademici
- âœ… **Unified Academic Dashboard**: Vista unificata del progresso didattico
- âœ… **Smart Recommendations**: Suggerimenti basati sui pattern di apprendimento

**ğŸ”§ Technical Enhancements:**
- âœ… **NetworkX Integration**: Libreria per visualizzazione grafi complessa
- âœ… **Optimized Graph Operations**: Performance elevate per big knowledge graphs
- âœ… **Scalable Entity Storage**: Database ottimizzato per migliaia di entity

**ğŸ“š Certification & Achievements:**
- âœ… **Study Streaks**: Ricompense per apprendimento consistente
- âœ… **Course Completion**: Badge per completamento corsi
- âœ… **Knowledge Master**: Traguardi per profonditÃ  di comprensione

### Versione 2.2.0 (Alpha 2.2) - Dicembre 2024

**ğŸ†• Nuove FunzionalitÃ :**
- âœ… Sistema di elaborazione asincrona Celery
- âœ… Containerizzazione Docker completa
- âœ… Dashboard di monitoraggio Flower
- âœ… Sistema di status in tempo reale

**ğŸ”§ Miglioramenti:**
- âœ… Ottimizzazione performance processamento
- âœ… Migliore gestione errori e recovery
- âœ… Interfaccia utente migliorata

### Versioni Precedenti

- **v1.0.0**: Release iniziale con funzionalitÃ  base

## ğŸ“ Supporto

### Community

- **GitHub Issues**: Segnala bug e richiedi feature
- **Discussions**: Discussioni sulla community
- **Documentation**: Controlla la documentazione aggiornata

### Contatti

- **Email**: support@archivista-ai.com
- **GitHub**: https://github.com/your-repo/archivista-ai
- **Documentation**: https://docs.archivista-ai.com

## ğŸ“„ Licenza

Questo progetto Ã¨ distribuito sotto licenza MIT. Vedi il file `LICENSE` per i dettagli.

## ğŸ™ Ringraziamenti

- **LlamaIndex Team**: Per l'eccellente framework AI
- **Streamlit Team**: Per l'interfaccia web intuitiva
- **Celery Team**: Per il sistema di task queue robusto
- **Open Source Community**: Per le librerie e tool utilizzati

---

**Archivista AI** - Porta l'intelligenza artificiale nel tuo archivio documentale ğŸš€
